{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/training/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/data/MNIST/mnist_train.csv\", header=None)\n",
    "df_test = pd.read_csv(\"/data/MNIST/mnist_test.csv\", header=None)\n",
    "\n",
    "y_train = df_train.iloc[:, 0].values\n",
    "y_test = df_test.iloc[:, 0].values\n",
    "X_train = df_train.iloc[:, 1:].values/255\n",
    "X_test = df_test.iloc[:, 1:].values/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Tensor(\"Placeholder:0\", shape=(?, 784), dtype=float32)\n",
      "y Tensor(\"Placeholder_1:0\", shape=(?,), dtype=int32)\n",
      "y_oh Tensor(\"one_hot:0\", shape=(?, 10), dtype=float32)\n",
      "A1 Tensor(\"Relu:0\", shape=(?, 100), dtype=float32)\n",
      "Z_out Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
      "y_pred Tensor(\"ArgMax:0\", shape=(?,), dtype=int32)\n",
      "match Tensor(\"Equal:0\", shape=(?,), dtype=bool)\n",
      "accuracy Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "loss Tensor(\"softmax_cross_entropy_with_logits/Reshape_2:0\", shape=(?,), dtype=float32)\n",
      "2.3459146\n",
      "2.2371297\n",
      "2.137779\n",
      "2.0465338\n",
      "1.9619101\n",
      "1.8822763\n",
      "1.806164\n",
      "1.732392\n",
      "1.6602029\n",
      "1.5892324\n",
      "1.519485\n",
      "1.4512701\n",
      "1.3849909\n",
      "1.3210576\n",
      "1.2598597\n",
      "1.2016159\n",
      "1.1464094\n",
      "1.0942796\n",
      "1.0452254\n",
      "0.99921834\n",
      "0.95622176\n",
      "0.91613775\n",
      "0.8788108\n",
      "0.84405243\n",
      "0.81169146\n",
      "0.7815399\n",
      "0.753449\n",
      "0.72729766\n",
      "0.7029654\n",
      "0.6803362\n",
      "0.6592973\n",
      "0.63972545\n",
      "0.62150574\n",
      "0.604525\n",
      "0.58866763\n",
      "0.5738581\n",
      "0.56000936\n",
      "0.5470519\n",
      "0.5349072\n",
      "0.5235027\n",
      "0.51278293\n",
      "0.50268984\n",
      "0.49318582\n",
      "0.4842301\n",
      "0.47578558\n",
      "0.4678097\n",
      "0.46026015\n",
      "0.4531031\n",
      "0.44630706\n",
      "0.4398431\n",
      "0.43368605\n",
      "0.42781347\n",
      "0.4222071\n",
      "0.41684857\n",
      "0.41172776\n",
      "0.4068319\n",
      "0.40214694\n",
      "0.39765826\n",
      "0.3933546\n",
      "0.38922083\n",
      "0.38524604\n",
      "0.38141862\n",
      "0.377732\n",
      "0.37417907\n",
      "0.37075314\n",
      "0.36744902\n",
      "0.3642595\n",
      "0.36117697\n",
      "0.3581964\n",
      "0.35531184\n",
      "0.3525165\n",
      "0.34980586\n",
      "0.34717298\n",
      "0.34461588\n",
      "0.34212956\n",
      "0.3397125\n",
      "0.3373593\n",
      "0.3350696\n",
      "0.33283845\n",
      "0.33066347\n",
      "0.32854205\n",
      "0.32647166\n",
      "0.32444948\n",
      "0.32247278\n",
      "0.32054016\n",
      "0.31864747\n",
      "0.3167955\n",
      "0.31498116\n",
      "0.31320292\n",
      "0.3114574\n",
      "0.3097449\n",
      "0.3080631\n",
      "0.30641028\n",
      "0.30478537\n",
      "0.30318666\n",
      "0.3016145\n",
      "0.3000662\n",
      "0.2985407\n",
      "0.2970394\n",
      "0.2955594\n",
      "Test accuracy:  0.9194833\n",
      "Test accuracy:  0.9198\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "n_x = X_train.shape[1]\n",
    "n_y = len(np.unique(y_train))\n",
    "n_h = 100\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, n_x))\n",
    "y = tf.placeholder(dtype=tf.int32, shape=(None,))\n",
    "print(\"X\", X)\n",
    "print(\"y\", y)\n",
    "\n",
    "y_oh = tf.one_hot(y, depth=n_y)\n",
    "print(\"y_oh\", y_oh)\n",
    "\n",
    "def dense_layer(input, size, activation = tf.nn.relu):\n",
    "    input_size = int(input.get_shape()[1])\n",
    "    W = tf.Variable(tf.truncated_normal(shape=(input_size, size), stddev=0.1))\n",
    "    b = tf.Variable(tf.zeros(shape=(size,)))\n",
    "    Z = tf.matmul(input, W) + b\n",
    "    \n",
    "    if callable(activation):\n",
    "        Z = activation(Z)\n",
    "    return Z\n",
    "\n",
    "\n",
    "A1 = dense_layer(X, n_h)\n",
    "print(\"A1\", A1)\n",
    "\n",
    "Z_out = dense_layer(A1, n_y, activation = None)\n",
    "print(\"Z_out\", Z_out)\n",
    "\n",
    "\n",
    "y_pred = tf.argmax(Z_out, axis=1, output_type=tf.int32)\n",
    "print(\"y_pred\", y_pred)\n",
    "\n",
    "match = tf.equal(y_pred, y)\n",
    "print(\"match\", match)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(match, tf.float32))\n",
    "print(\"accuracy\", accuracy)\n",
    "\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_oh, logits=Z_out)\n",
    "print(\"loss\", loss)\n",
    "\n",
    "cost = tf.reduce_mean(loss)\n",
    "\n",
    "op = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(100):\n",
    "        _, cost_ = sess.run([op, cost], feed_dict = {X: X_train, y: y_train})\n",
    "        \n",
    "        print(cost_)    \n",
    "    \n",
    "    train_accuracy = sess.run(accuracy, feed_dict = {X: X_train, y: y_train})\n",
    "    print(\"Test accuracy: \", train_accuracy)\n",
    "    \n",
    "    test_accuracy = sess.run(accuracy, feed_dict = {X: X_test, y: y_test})\n",
    "    print(\"Test accuracy: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
