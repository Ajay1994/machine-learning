{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulbasar/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/data/MNIST/mnist_train.csv\", header=None)\n",
    "df_test = pd.read_csv(\"/data/MNIST/mnist_test.csv\", header=None)\n",
    "\n",
    "y_train = df_train.iloc[:, 0].values\n",
    "y_test = df_test.iloc[:, 0].values\n",
    "X_train = df_train.iloc[:, 1:].values/255\n",
    "X_test = df_test.iloc[:, 1:].values/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Tensor(\"Placeholder:0\", shape=(?, 784), dtype=float32)\n",
      "y Tensor(\"Placeholder_1:0\", shape=(?,), dtype=int32)\n",
      "y_oh Tensor(\"one_hot:0\", shape=(?, 10), dtype=float32)\n",
      "A1 Tensor(\"Relu:0\", shape=(?, 100), dtype=float32)\n",
      "Z_out Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
      "y_pred Tensor(\"ArgMax:0\", shape=(?,), dtype=int32)\n",
      "match Tensor(\"Equal:0\", shape=(?,), dtype=bool)\n",
      "accuracy Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "loss Tensor(\"softmax_cross_entropy_with_logits/Reshape_2:0\", shape=(?,), dtype=float32)\n",
      "2.3459167\n",
      "2.2371323\n",
      "2.1377778\n",
      "2.0465329\n",
      "1.9619112\n",
      "1.8822734\n",
      "1.8061674\n",
      "1.732397\n",
      "1.6602042\n",
      "1.5892336\n",
      "1.5194873\n",
      "1.4512695\n",
      "1.3849896\n",
      "1.3210562\n",
      "1.2598606\n",
      "1.2016162\n",
      "1.1464095\n",
      "1.0942807\n",
      "1.0452243\n",
      "0.9992177\n",
      "0.9562212\n",
      "0.91613793\n",
      "0.8788108\n",
      "0.84405315\n",
      "0.8116923\n",
      "0.7815413\n",
      "0.7534504\n",
      "0.7272983\n",
      "0.70296615\n",
      "0.6803379\n",
      "0.6592984\n",
      "0.63972616\n",
      "0.62150586\n",
      "0.6045241\n",
      "0.5886688\n",
      "0.5738583\n",
      "0.560011\n",
      "0.5470528\n",
      "0.53490615\n",
      "0.5235032\n",
      "0.51278275\n",
      "0.5026907\n",
      "0.4931858\n",
      "0.48422965\n",
      "0.47578597\n",
      "0.46780977\n",
      "0.46026063\n",
      "0.45310378\n",
      "0.44630754\n",
      "0.43984318\n",
      "0.4336862\n",
      "0.42781407\n",
      "0.42220762\n",
      "0.41684917\n",
      "0.41172794\n",
      "0.40683156\n",
      "0.4021465\n",
      "0.3976586\n",
      "0.39335495\n",
      "0.38922083\n",
      "0.3852454\n",
      "0.3814185\n",
      "0.377732\n",
      "0.37417892\n",
      "0.37075338\n",
      "0.36744985\n",
      "0.3642596\n",
      "0.36117676\n",
      "0.35819674\n",
      "0.35531223\n",
      "0.3525173\n",
      "0.34980527\n",
      "0.34717292\n",
      "0.3446151\n",
      "0.34212968\n",
      "0.33971214\n",
      "0.33735982\n",
      "0.33506963\n",
      "0.3328385\n",
      "0.33066374\n",
      "0.32854205\n",
      "0.3264718\n",
      "0.3244498\n",
      "0.3224726\n",
      "0.32053912\n",
      "0.3186477\n",
      "0.31679526\n",
      "0.31498116\n",
      "0.31320313\n",
      "0.3114579\n",
      "0.3097451\n",
      "0.30806327\n",
      "0.3064103\n",
      "0.30478564\n",
      "0.3031874\n",
      "0.3016149\n",
      "0.30006623\n",
      "0.2985408\n",
      "0.29703927\n",
      "0.29555905\n",
      "Test accuracy:  0.9194833\n",
      "Test accuracy:  0.9198\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "n_x = X_train.shape[1]\n",
    "n_y = len(np.unique(y_train))\n",
    "n_h = 100\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, n_x))\n",
    "y = tf.placeholder(dtype=tf.int32, shape=(None,))\n",
    "print(\"X\", X)\n",
    "print(\"y\", y)\n",
    "\n",
    "y_oh = tf.one_hot(y, depth=n_y)\n",
    "print(\"y_oh\", y_oh)\n",
    "\n",
    "def dense_layer(input, size, activation = tf.nn.relu):\n",
    "    input_size = int(input.get_shape()[1])\n",
    "    W = tf.Variable(tf.truncated_normal(shape=(input_size, size), stddev=0.1))\n",
    "    b = tf.Variable(tf.zeros(shape=(size,)))\n",
    "    Z = tf.matmul(input, W) + b\n",
    "    \n",
    "    if callable(activation):\n",
    "        Z = activation(Z)\n",
    "    return Z\n",
    "\n",
    "\n",
    "A1 = dense_layer(X, n_h)\n",
    "print(\"A1\", A1)\n",
    "\n",
    "Z_out = dense_layer(A1, n_y, activation = None)\n",
    "print(\"Z_out\", Z_out)\n",
    "\n",
    "\n",
    "y_pred = tf.argmax(Z_out, axis=1, output_type=tf.int32)\n",
    "print(\"y_pred\", y_pred)\n",
    "\n",
    "match = tf.equal(y_pred, y)\n",
    "print(\"match\", match)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(match, tf.float32))\n",
    "print(\"accuracy\", accuracy)\n",
    "\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_oh, logits=Z_out)\n",
    "print(\"loss\", loss)\n",
    "\n",
    "cost = tf.reduce_mean(loss)\n",
    "\n",
    "op = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(100):\n",
    "        _, cost_ = sess.run([op, cost], feed_dict = {X: X_train, y: y_train})\n",
    "        \n",
    "        print(cost_)    \n",
    "    \n",
    "    train_accuracy = sess.run(accuracy, feed_dict = {X: X_train, y: y_train})\n",
    "    print(\"Test accuracy: \", train_accuracy)\n",
    "    \n",
    "    test_accuracy = sess.run(accuracy, feed_dict = {X: X_test, y: y_test})\n",
    "    print(\"Test accuracy: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye = np.eye(n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 16s 268us/step - loss: 0.1985 - acc: 0.9412 - val_loss: 0.1027 - val_acc: 0.9670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x122467be0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(units=400, activation=\"relu\", input_shape= (784,)))\n",
    "    model.add(keras.layers.Dense(units=100, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(units=n_y, activation=\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics = [\"accuracy\"], optimizer = \"adam\")\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.fit(X_train, eye[y_train], validation_data=(X_test, eye[y_test]), batch_size=32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 16s 259us/step - loss: 0.2364 - acc: 0.9291 - val_loss: 0.1327 - val_acc: 0.9597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1108640b8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(units=400, activation=\"tanh\", input_shape= (784,)))\n",
    "    model.add(keras.layers.Dense(units=100, activation=\"tanh\"))\n",
    "    model.add(keras.layers.Dense(units=n_y, activation=\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics = [\"accuracy\"], optimizer = \"adam\")\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.fit(X_train, eye[y_train], validation_data=(X_test, eye[y_test]), batch_size=32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 400)               640400    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 100)               40100     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 700,838\n",
      "Trainable params: 700,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 79s 1ms/step - loss: 0.1149 - acc: 0.9644 - val_loss: 0.0423 - val_acc: 0.9859\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 77s 1ms/step - loss: 0.0411 - acc: 0.9874 - val_loss: 0.0409 - val_acc: 0.9868\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 76s 1ms/step - loss: 0.0288 - acc: 0.9910 - val_loss: 0.0419 - val_acc: 0.9882\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 76s 1ms/step - loss: 0.0227 - acc: 0.9932 - val_loss: 0.0339 - val_acc: 0.9897\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 79s 1ms/step - loss: 0.0163 - acc: 0.9949 - val_loss: 0.0447 - val_acc: 0.9887\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 75s 1ms/step - loss: 0.0138 - acc: 0.9957 - val_loss: 0.0371 - val_acc: 0.9909\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 77s 1ms/step - loss: 0.0124 - acc: 0.9962 - val_loss: 0.0364 - val_acc: 0.9900\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.0104 - acc: 0.9970 - val_loss: 0.0343 - val_acc: 0.9913\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0106 - acc: 0.9968 - val_loss: 0.0360 - val_acc: 0.9924\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.0084 - acc: 0.9974 - val_loss: 0.0410 - val_acc: 0.9915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12dd19048>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(filters=32, kernel_size=(5, 5), activation=\"relu\", input_shape= (28,28,1)))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(units=400, activation=\"relu\", ))\n",
    "    model.add(keras.layers.Dense(units=100, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(units=n_y, activation=\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics = [\"accuracy\"], optimizer = \"adam\")\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "model.fit(X_train.reshape((-1, 28, 28, 1))\n",
    "          , eye[y_train]\n",
    "          , epochs=10\n",
    "          , validation_data=(X_test.reshape((-1, 28, 28, 1)), eye[y_test])\n",
    "          , batch_size=32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
